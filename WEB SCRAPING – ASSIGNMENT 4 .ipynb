{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.',\n",
       " '',\n",
       " '\"Tarzan Boy\"[56]',\n",
       " '\"Me at the zoo\"[57]',\n",
       " '\"Life Goes On\"[58]',\n",
       " '\"guitar\"[59]',\n",
       " '\"Hurt\"[60]',\n",
       " '\"Galinha Pintadinha – videoclip infantil animado\"[63]',\n",
       " '\"Ella y Yo\"[64]',\n",
       " '\"I Write Sins Not Tragedies\"[65]',\n",
       " '\"Evolution of Dance\"[66]',\n",
       " '\"Hit the Road Jack\"[67]',\n",
       " '\"The Gummy Bear Song\"[70]',\n",
       " '\"Numb\"[71]',\n",
       " '\"Osito Gominola – Full Spanish Version – The Gummy Bear Song\"[72]',\n",
       " '\"Charlie Bit My Finger\"[73]',\n",
       " '\"What I\\'ve Done\"[74]',\n",
       " '\"Bohemian Rhapsody\"[75]',\n",
       " '\"Hot n Cold\"[76]',\n",
       " '\"Pintinho Amarelinho – DVD Galena Pintadinha\"[77]',\n",
       " '\"Viva la Vida\"[78]',\n",
       " '\"Don\\'t Stop Me Now\"[79]',\n",
       " '\"Axel F\"[80]',\n",
       " '\"November Rain\"[81]',\n",
       " '\"Bad Romance\"[82]',\n",
       " '\"Smells Like Teen Spirit\"[83]',\n",
       " '\"Sweet Child o\\' Mine\"[84]',\n",
       " '\"Waka Waka (This Time for Africa)\"[54]',\n",
       " '\"Baby\"[85]',\n",
       " '\"Love the Way You Lie\"[86]',\n",
       " '\"Rolling in the Deep\"[87]',\n",
       " '\"Just the Way You Are\"[88]',\n",
       " '\"The Lazy Song\"[89]',\n",
       " '\"Party Rock Anthem\"[90]',\n",
       " '\"A Thousand Years\"[91]',\n",
       " '\"Hanuman Chalisa\"',\n",
       " '\"On the Floor\"[92]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[30]',\n",
       " '\"Gangnam Style\"[34]',\n",
       " '\"Let Her Go\"[50]',\n",
       " '\"Diamonds\"[93]',\n",
       " '\"Thrift Shop\"[94]',\n",
       " '\"Roar\"[40]',\n",
       " '\"Counting Stars\"[41]',\n",
       " '\"Wake Me Up\"[95]',\n",
       " '\"Rude\"[96]',\n",
       " '\"All of Me\"[97]',\n",
       " '\"Uptown Funk\"[31]',\n",
       " '\"Phonics Song with Two Words\"[36]',\n",
       " '\"Thinking Out Loud\"[42]',\n",
       " '\"Shake It Off\"[46]',\n",
       " '\"Bailando\"[49]',\n",
       " '\"See You Again\"[27]',\n",
       " '\"Sugar\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Faded\"[44]',\n",
       " '\"Lean On\"[47]',\n",
       " '\"Baby Shark Dance\"[22]',\n",
       " '\"Johny Johny Yes Papa\"[25]',\n",
       " '\"Closer (Lyric video)\"[98]',\n",
       " '\"Chantaje\"[99]',\n",
       " '\"We Don\\'t Talk Anymore\"[100]',\n",
       " '\"Despacito\"[24]',\n",
       " '\"Shape of You\"[26]',\n",
       " '\"Mi Gente\"[51]',\n",
       " '\"Perfect\"[52]',\n",
       " '\"New Rules\"[101]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[32]',\n",
       " '\"Bath Song\"[33]',\n",
       " '\"Dame Tu Cosita\"[39]',\n",
       " '\"Girls Like You\"[48]',\n",
       " '\"Wheels on the Bus\"[102]',\n",
       " '\"Con Calma\"[103]',\n",
       " '\"Con Altura\"[104]',\n",
       " '\"China\"[105]',\n",
       " '\"Dance Monkey\"[106]',\n",
       " '\"Numbers Song\"[107]',\n",
       " '\"Life Is Good\"[108]',\n",
       " '\"Dynamite\"[109]',\n",
       " '\"52 Gaj Ka Daman\"[110]',\n",
       " '\"How You Like That\"[111]',\n",
       " '\"Genda Phool\"[112]',\n",
       " 'TBA',\n",
       " '\"Baby Shark Dance\"[22]',\n",
       " '\"Despacito\"[24]',\n",
       " '\"See You Again\"[27]',\n",
       " '\"Gangnam Style\"⁂[34]',\n",
       " '\"Baby\"*[85]',\n",
       " '\"Bad Romance\"[82]',\n",
       " '\"Charlie Bit My Finger\"[73]',\n",
       " '\"Evolution of Dance\"[66]',\n",
       " '\"Girlfriend\"‡[122][123]',\n",
       " '\"Evolution of Dance\"[66]',\n",
       " '\"Music Is My Hot Hot Sex\"‡[126]',\n",
       " '\"Evolution of Dance\"*[66]',\n",
       " '\"Pokemon Theme Music Video\"‡[131]',\n",
       " '\"Myspace – The Movie\"‡[135][136]',\n",
       " '\"Phony Photo Booth\"‡[138]',\n",
       " '\"The Chronic of Narnia Rap\"‡[140]',\n",
       " '\"Ronaldinho: Touch of Gold\"‡*[142]',\n",
       " '\"I/O Brush\"‡*[145]',\n",
       " '\"Me at the zoo\"[57]',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Most-followed Facebook pages Most-followed Instagram accounts Most-followed TikTok accounts Most-followed Twitch channels Most-followed Twitter accounts YouTube channels Most-subscribed Most-viewed',\n",
       " 'Most-liked Instagram posts Most-liked TikTok videos Tweets Most-liked Most-retweeted Most-viewed online videos in the first 24 hours YouTube videos Most-liked Most-viewed Most-disliked']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "table=driver.find_element_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[1]\")\n",
    "tbody=table.find_element_by_tag_name(\"tbody\")\n",
    "tr=tbody.find_element_by_xpath(\"//tr[1]\")\n",
    "\n",
    "rank=tr.find_elements_by_xpath(\"//td[1]\")\n",
    "for i in rank:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)     \n",
    "\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "#international \n",
    "international=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']\")\n",
    "international.click()\n",
    "\n",
    "\n",
    "#fixtures\n",
    "fixture=international.find_element_by_xpath(\"//a[@class='navigation__link navigation__link--in-drop-down']\")\n",
    "fixture.click()\n",
    "\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Month=[]\n",
    "Time=[]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match title\n",
    "title=driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "for i in title:\n",
    "    Match_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series\n",
    "series=driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]')\n",
    "for i in series:\n",
    "    Series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place\n",
    "place=driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span[1]')\n",
    "for i in place:\n",
    "    Place.append(i.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date\n",
    "day=driver.find_elements_by_xpath('//span[@class=\"fixture__date\"]')\n",
    "for i in day:\n",
    "    Date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month\n",
    "month=driver.find_elements_by_xpath('//span[@class=\"fixture__month\"]')\n",
    "for i in month:\n",
    "    Month.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time\n",
    "time=driver.find_elements_by_xpath(\"//span[@class='fixture__time']\")\n",
    "for i in time:\n",
    "    Time.append(i.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>18</td>\n",
       "      <td>JUNE</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>13</td>\n",
       "      <td>JULY</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>16</td>\n",
       "      <td>JULY</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>18</td>\n",
       "      <td>JULY</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>21</td>\n",
       "      <td>JULY</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>23</td>\n",
       "      <td>JULY</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>25</td>\n",
       "      <td>JULY</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match title                       Series                         Place  \\\n",
       "0        Final  ICC WORLD TEST CHAMPIONSHIP   The Ageas Bowl, Southampton   \n",
       "1      1st ODI       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "2      2nd ODI       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "3      3rd ODI       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "4     1st T20I       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "5     2nd T20I       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "6     3rd T20I       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "7     1st Test         ENGLAND V INDIA 2021      Trent Bridge, Nottingham   \n",
       "8     2nd Test         ENGLAND V INDIA 2021                Lord's, London   \n",
       "9     3rd Test         ENGLAND V INDIA 2021             Headingley, Leeds   \n",
       "10    4th Test         ENGLAND V INDIA 2021              The Oval, London   \n",
       "11    5th Test         ENGLAND V INDIA 2021      Old Trafford, Manchester   \n",
       "\n",
       "   Date      Month       Time  \n",
       "0    18       JUNE  15:00 IST  \n",
       "1    13       JULY  14:30 IST  \n",
       "2    16       JULY  14:30 IST  \n",
       "3    18       JULY  14:30 IST  \n",
       "4    21       JULY  19:00 IST  \n",
       "5    23       JULY  19:00 IST  \n",
       "6    25       JULY  19:00 IST  \n",
       "7    04     AUGUST  15:30 IST  \n",
       "8    12     AUGUST  15:30 IST  \n",
       "9    25     AUGUST  15:30 IST  \n",
       "10   02  SEPTEMBER  15:30 IST  \n",
       "11   10  SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df[\"Match title\"]=Match_title\n",
    "df[\"Series\"]=Series\n",
    "df[\"Place\"]=Place\n",
    "df[\"Date\"]=Date\n",
    "df[\"Month\"]=Month\n",
    "df[\"Time\"]=Time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"India’s international fixtures 2021.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.guru99.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium \n",
    "selenium=driver.find_element_by_xpath(\"//li[3][@class='fa fa-chevron-circle-right']\")\n",
    "selenium.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exceptions\n",
    "exceptions=driver.find_element_by_xpath(\"//*[@id='g-mainbar']/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a\")\n",
    "exceptions.click()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=driver.find_element_by_xpath(\"//table[@class='table table-striped']\")\n",
    "tbody=table.find_element_by_tag_name(\"tbody\")\n",
    "rows=tbody.find_element_by_xpath(\"tr[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=rows.find_elements_by_xpath(\"//td[1]\")\n",
    "for i in name:\n",
    "    Name.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "description=rows.find_elements_by_xpath(\"//td[2]\")\n",
    "for i in description:\n",
    "    Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name =  ['Exception name', 'ElementNotVisibleException', 'ElementNotSelectableException', 'NoSuchElementException', 'NoSuchFrameException', 'NoAlertPresentException', 'NoSuchWindowException', 'StaleElementReferenceException', 'SessionNotFoundException', 'TimeoutException', 'WebDriverException', 'ConnectionClosedException', 'ElementClickInterceptedException', 'ElementNotInteractableException', 'ErrorInResponseException', 'ErrorHandler.UnknownServerException', 'ImeActivationFailedException', 'ImeNotAvailableException', 'InsecureCertificateException', 'InvalidArgumentException', 'InvalidCookieDomainException', 'InvalidCoordinatesException', 'InvalidElementStateExceptio', 'InvalidSessionIdException', 'InvalidSwitchToTargetException', 'JavascriptException', 'JsonException', 'NoSuchAttributeException', 'MoveTargetOutOfBoundsException', 'NoSuchContextException', 'NoSuchCookieException', 'NotFoundException', 'RemoteDriverServerException', 'ScreenshotException', 'SessionNotCreatedException', 'UnableToSetCookieException', 'UnexpectedTagNameException', 'UnhandledAlertException', 'UnexpectedAlertPresentException', 'UnknownMethodException', 'UnreachableBrowserException', 'UnsupportedCommandException', '']\n",
      "\n",
      " Description =  ['Description', 'This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.', 'This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.', 'This Exception occurs if an element could not be found.', 'This Exception occurs if the frame target to be switched to does not exist.', 'This Exception occurs when you switch to no presented alert.', 'This Exception occurs if the window target to be switch does not exist.', 'This Selenium exception occurs happens when the web element is detached from the current DOM.', 'The WebDriver is acting after you quit the browser.', \"Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.\", 'This Exception takes place when the WebDriver is acting right after you close the browser.', 'This type of Exception takes place when there is a disconnection in the driver.', 'The command may not be completed as the element receiving the events is concealing the element which was requested clicked.', 'This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.', 'This happens while interacting with the Firefox extension or the remote driver server.', 'Exception is used as a placeholder in case if the server returns an error without a stack trace.', 'This expectation will occur when IME engine activation has failed.', 'It takes place when IME support is unavailable.', 'Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.', 'It occurs when an argument does not belong to the expected type.', 'This happens when you try to add a cookie under a different domain instead of current URL.', 'This type of Exception matches an interacting operation that is not valid.', \"It occurs when command can't be finished when the element is invalid.\", 'This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.', 'This occurs when the frame or window target to be switched does not exist.', 'This issue occurs while executing JavaScript given by the user.', 'It occurs when you afford to get the session when the session is not created.', 'This kind of Exception occurs when the attribute of an element could not be found.', 'It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.', 'ContextAware does mobile device testing.', 'This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.', 'This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.', 'This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.', 'It is not possible to capture a screen.', 'It happens when a new session could not be successfully created.', 'This occurs if a driver is unable to set a cookie.', 'Happens if a support class did not get a web element as expected.', 'This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.', 'It occurs when there is the appearance of an unexpected alert.', 'This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.', 'This Exception occurs only when the browser is not able to be opened or crashed because of some reason.', \"This occurs when remote WebDriver does n't send valid commands as expected.\", '']\n"
     ]
    }
   ],
   "source": [
    "print(\"Name = \",Name[3:])\n",
    "print(\"\\n\",\"Description = \",Description[3:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter economy of india page\n",
    "economy=driver.find_element_by_xpath(\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "economy.click()\n",
    "india=economy.find_element_by_xpath(\"//*[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter gdp of indian state\n",
    "gdp=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\") \n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_1=[]\n",
    "GSDP_2=[]\n",
    "Share=[]              \n",
    "GDP=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=driver.find_element_by_xpath(\"//table[@id='table_id']\")  \n",
    "tbody=table.find_element_by_xpath(\"//table[@id='table_id']\") \n",
    "rows = tbody.find_element_by_tag_name(\"tr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=  rows.find_elements_by_xpath(\"//td[@class='data1'][1]\")\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'India',\n",
       " 'Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Karnataka',\n",
       " 'Gujarat',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Telangana',\n",
       " 'Andhra Pradesh',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Jharkhand',\n",
       " 'Chhattisgarh',\n",
       " 'Uttarakhand',\n",
       " 'Himachal Pradesh',\n",
       " 'Jammu & Kashmir',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Manipur',\n",
       " 'Sikkim',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'India']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=rows.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "for i in state:\n",
    "    State.append(i.text)  \n",
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-',\n",
       " '',\n",
       " '-',\n",
       " '1,167,776',\n",
       " '1,015,735',\n",
       " '1,035,131',\n",
       " '-',\n",
       " '713,376',\n",
       " '630,693',\n",
       " '594,806',\n",
       " '595,605',\n",
       " '496,798',\n",
       " '-',\n",
       " '568,265',\n",
       " '514,983',\n",
       " '377,276',\n",
       " '374,015',\n",
       " '344,437',\n",
       " '-',\n",
       " '218,232',\n",
       " '210,837',\n",
       " '-',\n",
       " '107,171',\n",
       " '-',\n",
       " '56,810',\n",
       " '35,980',\n",
       " '-',\n",
       " '22,291',\n",
       " '23,564',\n",
       " '18,549',\n",
       " '17,060',\n",
       " '-',\n",
       " '-',\n",
       " '17,797',\n",
       " '-',\n",
       " '']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp_1=rows.find_elements_by_xpath(\"//td[@class='data'][3]\")\n",
    "for i in gsdp_1:\n",
    "    if i.text is None :\n",
    "        GSDP_1.append(\"--\") \n",
    "    else:\n",
    "        GSDP_1.append(i.text)\n",
    "GSDP_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-',\n",
       " '2,332,992',\n",
       " '1,465,361',\n",
       " '1,404,761',\n",
       " '1,351,553',\n",
       " '1,322,936',\n",
       " '995,502',\n",
       " '845,247',\n",
       " '782,370',\n",
       " '776,140',\n",
       " '737,156',\n",
       " '707,542',\n",
       " '704,529',\n",
       " '666,075',\n",
       " '486,776',\n",
       " '472,506',\n",
       " '428,031',\n",
       " '282,782',\n",
       " '271,990',\n",
       " '266,537',\n",
       " '221,871',\n",
       " '133,303',\n",
       " '129,877',\n",
       " '66,060',\n",
       " '44,835',\n",
       " '37,571',\n",
       " '31,415',\n",
       " '29,544',\n",
       " '25,323',\n",
       " '25,141',\n",
       " '24,534',\n",
       " '22,488',\n",
       " '20,947',\n",
       " '-']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp_2=rows.find_elements_by_xpath(\"//td[@class='data sorting_1' ]\")\n",
    "for i in gsdp_2:\n",
    "    if i.text is None :\n",
    "        GSDP_2.append(\"--\") \n",
    "    else:\n",
    "        GSDP_2.append(i.text)  \n",
    "GSDP_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,039,074',\n",
       " '1,215,307',\n",
       " '1,123,982',\n",
       " '1,186,379',\n",
       " '1,091,077',\n",
       " '739,525',\n",
       " '677,428',\n",
       " '621,301',\n",
       " '612,828',\n",
       " '522,009',\n",
       " '559,412',\n",
       " '590,569',\n",
       " '531,085',\n",
       " '375,651',\n",
       " '397,669',\n",
       " '376,877',\n",
       " '234,048',\n",
       " '231,182',\n",
       " '224,986',\n",
       " '193,273',\n",
       " '112,755',\n",
       " '117,851',\n",
       " '57,787',\n",
       " '36,963',\n",
       " '31,192',\n",
       " '23,013',\n",
       " '24,682',\n",
       " '18,722',\n",
       " '19,300',\n",
       " '17,647',\n",
       " '16,676',\n",
       " '16,478',\n",
       " '-',\n",
       " '14,569,268',\n",
       " '12,240,380']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share=rows.find_elements_by_xpath(\"//td[@class='data'][5]\")\n",
    "for i in share:\n",
    "    if i.text is None :\n",
    "        Share.append(\"--\") \n",
    "    else:\n",
    "        Share.append(i.text)\n",
    "Share  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,039,074',\n",
       " '1,215,307',\n",
       " '1,123,982',\n",
       " '1,186,379',\n",
       " '1,091,077',\n",
       " '739,525',\n",
       " '677,428',\n",
       " '621,301',\n",
       " '612,828',\n",
       " '522,009',\n",
       " '559,412',\n",
       " '590,569',\n",
       " '531,085',\n",
       " '375,651',\n",
       " '397,669',\n",
       " '376,877',\n",
       " '234,048',\n",
       " '231,182',\n",
       " '224,986',\n",
       " '193,273',\n",
       " '112,755',\n",
       " '117,851',\n",
       " '57,787',\n",
       " '36,963',\n",
       " '31,192',\n",
       " '23,013',\n",
       " '24,682',\n",
       " '18,722',\n",
       " '19,300',\n",
       " '17,647',\n",
       " '16,676',\n",
       " '16,478',\n",
       " '-',\n",
       " '14,569,268',\n",
       " '12,240,380']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp=rows.find_elements_by_xpath(\"//td[@class='data'][5]\")\n",
    "for i in gdp:\n",
    "    if i.text is None :\n",
    "        GDP.append(\"--\") \n",
    "    else:\n",
    "        GDP.append(i.text)\n",
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5.Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore to trending\n",
    "explore=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "explore.click()\n",
    "trending=explore.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jina-ai  ',\n",
       " 'willmcgugan  ',\n",
       " 'monyhar  ',\n",
       " 'programthink  ',\n",
       " 'jwasham  ',\n",
       " 'streamich  ',\n",
       " 'hasura  ',\n",
       " 'walidshaari  ',\n",
       " 'siduck76  ',\n",
       " 'trimstray  ',\n",
       " 'lydiahallie  ',\n",
       " 'IlanKalendarov  ',\n",
       " 'SuMaiKaDe  ',\n",
       " 'bitcoin  ',\n",
       " 'nushell  ',\n",
       " 'neovim  ',\n",
       " 'smokeme  ',\n",
       " 'RPwnage  ',\n",
       " 'BurntSushi  ',\n",
       " 'elastic  ',\n",
       " 'CyberPunkMetalHead  ',\n",
       " 'discordjs  ',\n",
       " 'atom  ',\n",
       " 'thanos-io  ',\n",
       " 'Asabeneh  ']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repository title\n",
    "title=driver.find_elements_by_xpath(\"//span[@class='text-normal']\")\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        Repository_title.append(\"--\") \n",
    "    else:\n",
    "        Repository_title.append(i.text.replace(\"/\",\" \"))    \n",
    "        \n",
    "Repository_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An easier way to build neural search on the cloud',\n",
       " 'Rich is a Python library for rich text and beautiful formatting in the terminal.',\n",
       " '梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺少上网功能。',\n",
       " '【编程随想】收藏的电子书清单（多个学科，含下载链接）',\n",
       " 'A complete computer science study plan to become a software engineer.',\n",
       " 'React Hooks — 👍',\n",
       " 'Blazing fast, instant realtime GraphQL APIs on your DB with fine grained access control, also trigger webhooks on database events.',\n",
       " 'Curated resources help you prepare for the CNCF/Linux Foundation CKS 2021 \"Kubernetes Certified Security Specialist\" Certification exam. Please provide feedback or requests by raising issues, or making a pull request. All feedback for improvements are welcome. thank you.',\n",
       " 'beautiful neovim setup configured in lua',\n",
       " 'A collection of inspiring lists, manuals, cheatsheets, blogs, hacks, one-liners, cli/web tools and more.',\n",
       " 'A long list of (advanced) JavaScript questions, and their explanations ✨',\n",
       " 'Bitcoin Core integration/staging tree',\n",
       " 'A new type of shell',\n",
       " 'Vim-fork focused on extensibility and usability',\n",
       " 'Generate obfuscated meterpreter shells',\n",
       " 'iOS 14.5 WebKit/Safari based Jailbreak',\n",
       " 'ripgrep recursively searches directories for a regex pattern while respecting your gitignore',\n",
       " 'Your window into the Elastic Stack',\n",
       " 'This is a simple backtesting framework to help you test your crypto currency trading. It includes a way to download and store historical crypto data and to execute a trading strategy.',\n",
       " 'A powerful JavaScript library for interacting with the Discord API',\n",
       " 'The hackable text editor',\n",
       " 'Highly available Prometheus setup with long term storage capabilities. A CNCF Incubating project.',\n",
       " '30 days of JavaScript programming challenge is a step-by-step guide to learn JavaScript programming language in 30 days. This challenge may take more than 100 days, please just follow your own pace.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repository description\n",
    "description=driver.find_elements_by_xpath(\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")\n",
    "for i in description:\n",
    "    if i.text is None :\n",
    "        Repository_description.append(\"--\") \n",
    "    else:\n",
    "        Repository_description.append(i.text) \n",
    "        \n",
    "Repository_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['501',\n",
       " '811',\n",
       " '37',\n",
       " '2,096',\n",
       " '48,732',\n",
       " '1,656',\n",
       " '1,903',\n",
       " '236',\n",
       " '83',\n",
       " '4,387',\n",
       " '4,514',\n",
       " '14',\n",
       " '69',\n",
       " '29,126',\n",
       " '592',\n",
       " '3,269',\n",
       " '6',\n",
       " '47',\n",
       " '1,133',\n",
       " '6,600',\n",
       " '7',\n",
       " '2,567',\n",
       " '16,178',\n",
       " '1,272',\n",
       " '1,770']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Contributors count\n",
    "count=driver.find_elements_by_xpath(\"//a[@class='Link--muted d-inline-block mr-3'][2]\")\n",
    "for i in count:\n",
    "    if i.text is None :\n",
    "        Contributors_count.append(\"--\") \n",
    "    else:\n",
    "        Contributors_count.append(i.text)\n",
    "        \n",
    "Contributors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'Python',\n",
       " 'C',\n",
       " 'TypeScript',\n",
       " 'Haskell',\n",
       " 'AGS Script',\n",
       " 'Lua',\n",
       " 'C#',\n",
       " 'Python',\n",
       " 'C++',\n",
       " 'Rust',\n",
       " 'Vim script',\n",
       " 'Python',\n",
       " 'JavaScript',\n",
       " 'Rust',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'Go',\n",
       " 'JavaScript']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Language used\n",
    "used=driver.find_elements_by_xpath(\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in used:\n",
    "    if i.text is None :\n",
    "        Language_used.append(\"--\") \n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "        \n",
    "Language_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 23 25 21\n"
     ]
    }
   ],
   "source": [
    "print(len(Repository_title),len(Repository_description),len(Contributors_count),len(Language_used))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jina-ai</td>\n",
       "      <td>An easier way to build neural search on the cloud</td>\n",
       "      <td>501</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willmcgugan</td>\n",
       "      <td>Rich is a Python library for rich text and bea...</td>\n",
       "      <td>811</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monyhar</td>\n",
       "      <td>梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...</td>\n",
       "      <td>37</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>programthink</td>\n",
       "      <td>【编程随想】收藏的电子书清单（多个学科，含下载链接）</td>\n",
       "      <td>2,096</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jwasham</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>48,732</td>\n",
       "      <td>Haskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>streamich</td>\n",
       "      <td>React Hooks — 👍</td>\n",
       "      <td>1,656</td>\n",
       "      <td>AGS Script</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hasura</td>\n",
       "      <td>Blazing fast, instant realtime GraphQL APIs on...</td>\n",
       "      <td>1,903</td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>walidshaari</td>\n",
       "      <td>Curated resources help you prepare for the CNC...</td>\n",
       "      <td>236</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>siduck76</td>\n",
       "      <td>beautiful neovim setup configured in lua</td>\n",
       "      <td>83</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trimstray</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>4,387</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lydiahallie</td>\n",
       "      <td>A long list of (advanced) JavaScript questions...</td>\n",
       "      <td>4,514</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IlanKalendarov</td>\n",
       "      <td>Bitcoin Core integration/staging tree</td>\n",
       "      <td>14</td>\n",
       "      <td>Vim script</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SuMaiKaDe</td>\n",
       "      <td>A new type of shell</td>\n",
       "      <td>69</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>Vim-fork focused on extensibility and usability</td>\n",
       "      <td>29,126</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nushell</td>\n",
       "      <td>Generate obfuscated meterpreter shells</td>\n",
       "      <td>592</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neovim</td>\n",
       "      <td>iOS 14.5 WebKit/Safari based Jailbreak</td>\n",
       "      <td>3,269</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>smokeme</td>\n",
       "      <td>ripgrep recursively searches directories for a...</td>\n",
       "      <td>6</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RPwnage</td>\n",
       "      <td>Your window into the Elastic Stack</td>\n",
       "      <td>47</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BurntSushi</td>\n",
       "      <td>This is a simple backtesting framework to help...</td>\n",
       "      <td>1,133</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>elastic</td>\n",
       "      <td>A powerful JavaScript library for interacting ...</td>\n",
       "      <td>6,600</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Repository title                             Repository description  \\\n",
       "0          jina-ai    An easier way to build neural search on the cloud   \n",
       "1      willmcgugan    Rich is a Python library for rich text and bea...   \n",
       "2          monyhar    梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...   \n",
       "3     programthink                           【编程随想】收藏的电子书清单（多个学科，含下载链接）   \n",
       "4          jwasham    A complete computer science study plan to beco...   \n",
       "5        streamich                                      React Hooks — 👍   \n",
       "6           hasura    Blazing fast, instant realtime GraphQL APIs on...   \n",
       "7      walidshaari    Curated resources help you prepare for the CNC...   \n",
       "8         siduck76             beautiful neovim setup configured in lua   \n",
       "9        trimstray    A collection of inspiring lists, manuals, chea...   \n",
       "10     lydiahallie    A long list of (advanced) JavaScript questions...   \n",
       "11  IlanKalendarov                Bitcoin Core integration/staging tree   \n",
       "12       SuMaiKaDe                                  A new type of shell   \n",
       "13         bitcoin      Vim-fork focused on extensibility and usability   \n",
       "14         nushell               Generate obfuscated meterpreter shells   \n",
       "15          neovim               iOS 14.5 WebKit/Safari based Jailbreak   \n",
       "16         smokeme    ripgrep recursively searches directories for a...   \n",
       "17         RPwnage                   Your window into the Elastic Stack   \n",
       "18      BurntSushi    This is a simple backtesting framework to help...   \n",
       "19         elastic    A powerful JavaScript library for interacting ...   \n",
       "\n",
       "   Contributors count Language used  \n",
       "0                 501        Python  \n",
       "1                 811        Python  \n",
       "2                  37             C  \n",
       "3               2,096    TypeScript  \n",
       "4              48,732       Haskell  \n",
       "5               1,656    AGS Script  \n",
       "6               1,903           Lua  \n",
       "7                 236            C#  \n",
       "8                  83        Python  \n",
       "9               4,387           C++  \n",
       "10              4,514          Rust  \n",
       "11                 14    Vim script  \n",
       "12                 69        Python  \n",
       "13             29,126    JavaScript  \n",
       "14                592          Rust  \n",
       "15              3,269    TypeScript  \n",
       "16                  6        Python  \n",
       "17                 47    JavaScript  \n",
       "18              1,133    JavaScript  \n",
       "19              6,600            Go  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Repository title']=Repository_title[0:20]\n",
    "df['Repository description']=Repository_description[0:20]\n",
    "df['Contributors count']=Contributors_count[0:20]\n",
    "df['Language used']=Language_used[0:20]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Trending repositories on Github.csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6.Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billiboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/charts/hot-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Butter',\n",
       " 'Good 4 U',\n",
       " 'Levitating',\n",
       " 'Peaches',\n",
       " 'Leave The Door Open',\n",
       " 'Save Your Tears',\n",
       " 'Kiss Me More',\n",
       " 'Astronaut In The Ocean',\n",
       " 'Deja Vu',\n",
       " 'Yonaguni',\n",
       " 'Montero (Call Me By Your Name)',\n",
       " 'Without You',\n",
       " 'Forever After All',\n",
       " 'Rapstar',\n",
       " 'Blinding Lights',\n",
       " 'Hats Off',\n",
       " 'Drivers License',\n",
       " 'Beautiful Mistakes',\n",
       " 'Traitor',\n",
       " 'Late At Night',\n",
       " 'Voice Of The Heroes',\n",
       " 'Best Friend',\n",
       " 'Heartbreak Anniversary',\n",
       " 'Heat Waves',\n",
       " 'Calling My Phone',\n",
       " 'Favorite Crime',\n",
       " 'Lost Cause',\n",
       " 'Happier',\n",
       " 'Up',\n",
       " 'Mood',\n",
       " '2040',\n",
       " 'Every Chance I Get',\n",
       " 'Telepatia',\n",
       " 'How It Feels',\n",
       " 'Brutal',\n",
       " 'Wockesha',\n",
       " 'Wants And Needs',\n",
       " 'Famous Friends',\n",
       " 'pov',\n",
       " 'Gone',\n",
       " 'Beat Box',\n",
       " \"My Ex's Best Friend\",\n",
       " 'Still Runnin',\n",
       " 'Track Star',\n",
       " 'What You Know Bout Love',\n",
       " 'Who I Want',\n",
       " 'my.life',\n",
       " 'Back In Blood',\n",
       " 'Time Today',\n",
       " 'Lil Bit',\n",
       " 'Blame It On You',\n",
       " 'Nobody',\n",
       " 'Todo de Ti',\n",
       " 'Enough For You',\n",
       " 'Settling Down',\n",
       " 'Still Hood',\n",
       " 'Jealousy, Jealousy',\n",
       " 'Okay',\n",
       " 'Almost Maybes',\n",
       " 'Man Of My Word',\n",
       " 'Build A Bitch',\n",
       " \"Breaking Up Was Easy In The 90's\",\n",
       " 'Glad You Exist',\n",
       " 'pride.is.the.devil',\n",
       " '1 Step Forward, 3 Steps Back',\n",
       " 'Ski',\n",
       " 'Medical',\n",
       " 'Rich Off Pain',\n",
       " 'Leave Before You Love Me',\n",
       " 'Lying',\n",
       " 'Snowflakes',\n",
       " 'Single Saturday Night',\n",
       " \"That's Facts\",\n",
       " 'Made For You',\n",
       " 'Your Power',\n",
       " 'No More Parties',\n",
       " \"We're Good\",\n",
       " 'One Too Many',\n",
       " 'Please',\n",
       " 'Up The Side',\n",
       " 'Minimum Wage',\n",
       " 'Miss The Rage',\n",
       " 'Way Less Sad',\n",
       " 'Hope Ur OK',\n",
       " 'Quicksand',\n",
       " 'Arcade',\n",
       " 'Straightenin',\n",
       " 'Gang Gang',\n",
       " \"Drinkin' Beer. Talkin' God. Amen.\",\n",
       " 'Follow You',\n",
       " 'Chasing After You',\n",
       " 'Tell Em',\n",
       " '4 Da Gang',\n",
       " 'Tombstone',\n",
       " \"What's Next\",\n",
       " 'Things A Man Oughta Know',\n",
       " 'Country Again',\n",
       " \"Drunk (And I Don't Wanna Go Home)\",\n",
       " 'If You Want To',\n",
       " 'Seeing Green']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Song Name\n",
    "name=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in name:\n",
    "    if i.text is None :\n",
    "        Song_name.append(\"--\") \n",
    "    else:\n",
    "        Song_name.append(i.text.replace(\"/\",\" \"))\n",
    "        \n",
    "Song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTS',\n",
       " 'Olivia Rodrigo',\n",
       " 'Dua Lipa Featuring DaBaby',\n",
       " 'Justin Bieber Featuring Daniel Caesar & Giveon',\n",
       " 'Silk Sonic (Bruno Mars & Anderson .Paak)',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Doja Cat Featuring SZA',\n",
       " 'Masked Wolf',\n",
       " 'Olivia Rodrigo',\n",
       " 'Bad Bunny',\n",
       " 'Lil Nas X',\n",
       " 'The Kid LAROI',\n",
       " 'Luke Combs',\n",
       " 'Polo G',\n",
       " 'The Weeknd',\n",
       " 'Lil Baby, Lil Durk & Travis Scott',\n",
       " 'Olivia Rodrigo',\n",
       " 'Maroon 5 Featuring Megan Thee Stallion',\n",
       " 'Olivia Rodrigo',\n",
       " 'Roddy Ricch',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Saweetie Featuring Doja Cat',\n",
       " 'Giveon',\n",
       " 'Glass Animals',\n",
       " 'Lil Tjay Featuring 6LACK',\n",
       " 'Olivia Rodrigo',\n",
       " 'Billie Eilish',\n",
       " 'Olivia Rodrigo',\n",
       " 'Cardi B',\n",
       " '24kGoldn Featuring iann dior',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'DJ Khaled Featuring Lil Baby & Lil Durk',\n",
       " 'Kali Uchis',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Olivia Rodrigo',\n",
       " 'Moneybagg Yo',\n",
       " 'Drake Featuring Lil Baby',\n",
       " 'Chris Young + Kane Brown',\n",
       " 'Ariana Grande',\n",
       " 'Dierks Bentley',\n",
       " 'SpotemGottem Featuring Pooh Shiesty Or DaBaby',\n",
       " 'Machine Gun Kelly X blackbear',\n",
       " 'Lil Baby, Lil Durk & Meek Mill',\n",
       " 'Mooski',\n",
       " 'Pop Smoke',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'J. Cole, 21 Savage & Morray',\n",
       " 'Pooh Shiesty Featuring Lil Durk',\n",
       " 'Moneybagg Yo',\n",
       " 'Nelly & Florida Georgia Line',\n",
       " 'Jason Aldean',\n",
       " 'Dylan Scott',\n",
       " 'Rauw Alejandro',\n",
       " 'Olivia Rodrigo',\n",
       " 'Miranda Lambert',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Olivia Rodrigo',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Jordan Davis',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Bella Poarch',\n",
       " 'Sam Hunt',\n",
       " 'Dan + Shay',\n",
       " 'J. Cole & Lil Baby',\n",
       " 'Olivia Rodrigo',\n",
       " 'Young Thug & Gunna',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Lil Baby, Lil Durk & Rod Wave',\n",
       " 'Marshmello X Jonas Brothers',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Tom MacDonald',\n",
       " 'Cole Swindell',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Jake Owen',\n",
       " 'Billie Eilish',\n",
       " 'Coi Leray Featuring Lil Durk',\n",
       " 'Dua Lipa',\n",
       " 'Keith Urban Duet With P!nk',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Lil Baby, Lil Durk & Young Thug',\n",
       " 'Blake Shelton',\n",
       " 'Trippie Redd & Playboi Carti',\n",
       " 'AJR',\n",
       " 'Olivia Rodrigo',\n",
       " 'Morray',\n",
       " 'Duncan Laurence',\n",
       " 'Migos',\n",
       " 'Polo G & Lil Wayne',\n",
       " 'Chase Rice Featuring Florida Georgia Line',\n",
       " 'Imagine Dragons',\n",
       " 'Ryan Hurd With Maren Morris',\n",
       " 'Cochise & $NOT',\n",
       " '42 Dugg & Roddy Ricch',\n",
       " 'Rod Wave',\n",
       " 'Drake',\n",
       " 'Lainey Wilson',\n",
       " 'Thomas Rhett',\n",
       " 'Elle King & Miranda Lambert',\n",
       " 'Lil Baby & Lil Durk',\n",
       " 'Nicki Minaj, Drake & Lil Wayne']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Artist Name\n",
    "artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in artist:\n",
    "    if i.text is None :\n",
    "        Artist_name.append(\"--\") \n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "        \n",
    "Artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '6',\n",
       " '3',\n",
       " '10',\n",
       " '1',\n",
       " '8',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '16',\n",
       " '1',\n",
       " '18',\n",
       " '9',\n",
       " '20',\n",
       " '21',\n",
       " '14',\n",
       " '17',\n",
       " '24',\n",
       " '3',\n",
       " '16',\n",
       " '27',\n",
       " '15',\n",
       " '1',\n",
       " '1',\n",
       " '31',\n",
       " '20',\n",
       " '33',\n",
       " '34',\n",
       " '12',\n",
       " '33',\n",
       " '2',\n",
       " '38',\n",
       " '37',\n",
       " '36',\n",
       " '12',\n",
       " '20',\n",
       " '43',\n",
       " '31',\n",
       " '9',\n",
       " '46',\n",
       " '2',\n",
       " '13',\n",
       " '31',\n",
       " '50',\n",
       " '51',\n",
       " '50',\n",
       " '53',\n",
       " '14',\n",
       " '47',\n",
       " '56',\n",
       " '24',\n",
       " '58',\n",
       " '51',\n",
       " '60',\n",
       " '56',\n",
       " '32',\n",
       " '63',\n",
       " '7',\n",
       " '19',\n",
       " '18',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '70',\n",
       " '73',\n",
       " '32',\n",
       " '10',\n",
       " '26',\n",
       " '31',\n",
       " '62',\n",
       " '79',\n",
       " '80',\n",
       " '69',\n",
       " '11',\n",
       " '77',\n",
       " '29',\n",
       " '65',\n",
       " '78',\n",
       " '38',\n",
       " '33',\n",
       " '75',\n",
       " '68',\n",
       " '87',\n",
       " '64',\n",
       " '67',\n",
       " '11',\n",
       " '1',\n",
       " '93',\n",
       " '73',\n",
       " '79',\n",
       " '99',\n",
       " '12']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peak rank\n",
    "peak=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:\n",
    "    if i.text is None :\n",
    "        Last_week_rank.append(\"--\") \n",
    "    else:\n",
    "        Last_week_rank.append(i.text)\n",
    "        \n",
    "Last_week_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '6',\n",
       " '4',\n",
       " '5',\n",
       " '7',\n",
       " '9',\n",
       " '8',\n",
       " '-',\n",
       " '10',\n",
       " '11',\n",
       " '15',\n",
       " '14',\n",
       " '17',\n",
       " '-',\n",
       " '13',\n",
       " '18',\n",
       " '12',\n",
       " '-',\n",
       " '81',\n",
       " '22',\n",
       " '23',\n",
       " '25',\n",
       " '21',\n",
       " '16',\n",
       " '-',\n",
       " '20',\n",
       " '24',\n",
       " '30',\n",
       " '-',\n",
       " '26',\n",
       " '34',\n",
       " '-',\n",
       " '19',\n",
       " '33',\n",
       " '39',\n",
       " '43',\n",
       " '37',\n",
       " '36',\n",
       " '29',\n",
       " '31',\n",
       " '-',\n",
       " '32',\n",
       " '41',\n",
       " '-',\n",
       " '28',\n",
       " '35',\n",
       " '48',\n",
       " '53',\n",
       " '63',\n",
       " '50',\n",
       " '66',\n",
       " '27',\n",
       " '47',\n",
       " '-',\n",
       " '42',\n",
       " '-',\n",
       " '51',\n",
       " '-',\n",
       " '56',\n",
       " '49',\n",
       " '68',\n",
       " '45',\n",
       " '38',\n",
       " '55',\n",
       " '-',\n",
       " '-',\n",
       " '72',\n",
       " '-',\n",
       " '-',\n",
       " '70',\n",
       " '-',\n",
       " '57',\n",
       " '60',\n",
       " '59',\n",
       " '54',\n",
       " '71',\n",
       " '-',\n",
       " '-',\n",
       " '69',\n",
       " '58',\n",
       " '77',\n",
       " '52',\n",
       " '73',\n",
       " '85',\n",
       " '78',\n",
       " '61',\n",
       " '75',\n",
       " '86',\n",
       " '87',\n",
       " '64',\n",
       " '74',\n",
       " '79',\n",
       " '76',\n",
       " '93',\n",
       " '89',\n",
       " '92',\n",
       " '-',\n",
       " '67']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last week rank\n",
    "last_rank=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in last_rank:\n",
    "    if i.text is None :\n",
    "        Peak_rank.append(\"--\") \n",
    "    else:\n",
    "        Peak_rank.append(i.text)\n",
    "        \n",
    "Peak_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " '4',\n",
       " '36',\n",
       " '12',\n",
       " '14',\n",
       " '26',\n",
       " '9',\n",
       " '17',\n",
       " '10',\n",
       " '1',\n",
       " '11',\n",
       " '27',\n",
       " '33',\n",
       " '9',\n",
       " '79',\n",
       " '1',\n",
       " '22',\n",
       " '14',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '22',\n",
       " '17',\n",
       " '21',\n",
       " '17',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '18',\n",
       " '44',\n",
       " '1',\n",
       " '6',\n",
       " '16',\n",
       " '1',\n",
       " '3',\n",
       " '7',\n",
       " '14',\n",
       " '11',\n",
       " '14',\n",
       " '13',\n",
       " '21',\n",
       " '43',\n",
       " '1',\n",
       " '16',\n",
       " '40',\n",
       " '1',\n",
       " '4',\n",
       " '23',\n",
       " '18',\n",
       " '12',\n",
       " '7',\n",
       " '15',\n",
       " '2',\n",
       " '3',\n",
       " '13',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '20',\n",
       " '1',\n",
       " '4',\n",
       " '15',\n",
       " '18',\n",
       " '4',\n",
       " '3',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '16',\n",
       " '6',\n",
       " '18',\n",
       " '17',\n",
       " '26',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '5',\n",
       " '7',\n",
       " '3',\n",
       " '18',\n",
       " '9',\n",
       " '4',\n",
       " '3',\n",
       " '2',\n",
       " '10',\n",
       " '7',\n",
       " '2',\n",
       " '10',\n",
       " '12',\n",
       " '14',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '1',\n",
       " '4']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weeks on board\n",
    "weeks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in weeks:\n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\") \n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "        \n",
    "Weeks_on_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song_name),len(Artist_name),len(Last_week_rank),len(Peak_rank),len(Weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>73</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td>99</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song name  \\\n",
       "0                              Butter   \n",
       "1                            Good 4 U   \n",
       "2                          Levitating   \n",
       "3                             Peaches   \n",
       "4                 Leave The Door Open   \n",
       "..                                ...   \n",
       "95           Things A Man Oughta Know   \n",
       "96                      Country Again   \n",
       "97  Drunk (And I Don't Wanna Go Home)   \n",
       "98                     If You Want To   \n",
       "99                       Seeing Green   \n",
       "\n",
       "                                       Artist name Last week rank Peak rank  \\\n",
       "0                                              BTS              1         1   \n",
       "1                                   Olivia Rodrigo              1         2   \n",
       "2                        Dua Lipa Featuring DaBaby              2         3   \n",
       "3   Justin Bieber Featuring Daniel Caesar & Giveon              1         6   \n",
       "4         Silk Sonic (Bruno Mars & Anderson .Paak)              1         4   \n",
       "..                                             ...            ...       ...   \n",
       "95                                   Lainey Wilson             93        93   \n",
       "96                                    Thomas Rhett             73        89   \n",
       "97                     Elle King & Miranda Lambert             79        92   \n",
       "98                             Lil Baby & Lil Durk             99         -   \n",
       "99                  Nicki Minaj, Drake & Lil Wayne             12        67   \n",
       "\n",
       "   Weeks on board  \n",
       "0               3  \n",
       "1               4  \n",
       "2              36  \n",
       "3              12  \n",
       "4              14  \n",
       "..            ...  \n",
       "95              4  \n",
       "96              6  \n",
       "97              7  \n",
       "98              1  \n",
       "99              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df[\"Song name\"]=Song_name[0:100]\n",
    "df[\"Artist name\"]=Artist_name[0:100]\n",
    "df[\"Last week rank\"]=Last_week_rank\n",
    "df[\"Peak rank\"]=Peak_rank\n",
    "df[\"Weeks on board\"]=Weeks_on_board    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Top 100 songs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7.Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating search_bar by id\n",
    "search_bar = driver.find_element_by_xpath(\"//input[@class='sugInp']\") \n",
    "search_bar.send_keys(\"Data science\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "\n",
    "job_name=[]\n",
    "Designation = []\n",
    "company_name=[]\n",
    "Skills_they_hire_for = []\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Science Engineer',\n",
       " 'BUSINESS ANALYST -DATA SCIENCE-CONSUMER',\n",
       " 'Data Science Analyst',\n",
       " 'Data Science Analyst 2',\n",
       " 'Data Science- Associate Data Scientist',\n",
       " 'Data Science Intern (remote)',\n",
       " 'Senior Software Developer - NLP/ Machine Learning/ Data Science',\n",
       " 'Senior Software Developer - Nlp/machine Learning/data Science',\n",
       " 'Data Science Analyst',\n",
       " 'Urgently hiring For Data science Analysts - Pune - 4+ Yrs',\n",
       " 'Opening For Data Data Science Analyst & Data Analyst',\n",
       " 'Analyst -Data Science ( Supply Chain)',\n",
       " 'Data Science & Analysis (Technology Management)',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Web Development/Data Science Trainee',\n",
       " 'Data Science Engineer',\n",
       " 'Data Science Engineer',\n",
       " 'Data Science Analyst-Insurance Data Sciences']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_name.append(\"--\") \n",
    "    else:\n",
    "        job_name.append(i.text)\n",
    "        \n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Science Engineer',\n",
       " 'BUSINESS ANALYST -DATA SCIENCE-CONSUMER',\n",
       " 'Data Science Analyst',\n",
       " 'Data Science Analyst 2',\n",
       " 'Data Science- Associate Data Scientist',\n",
       " 'Data Science Intern (remote)',\n",
       " 'Senior Software Developer - NLP/ Machine Learning/ Data Science',\n",
       " 'Senior Software Developer - Nlp/machine Learning/data Science',\n",
       " 'Data Science Analyst',\n",
       " 'Urgently hiring For Data science Analysts - Pune - 4+ Yrs',\n",
       " 'Opening For Data Data Science Analyst & Data Analyst',\n",
       " 'Analyst -Data Science ( Supply Chain)',\n",
       " 'Data Science & Analysis (Technology Management)',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Web Development/Data Science Trainee',\n",
       " 'Data Science Engineer',\n",
       " 'Data Science Engineer',\n",
       " 'Data Science Analyst-Insurance Data Sciences']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designation=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in designation:\n",
    "    if i.text is None :\n",
    "        Designation.append(\"--\") \n",
    "    else:\n",
    "        Designation.append(i.text)\n",
    "Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune',\n",
       " 'Nagpur, Pune, Mumbai (All Areas)',\n",
       " 'Mumbai, Navi Mumbai, Mumbai (All Areas)',\n",
       " 'Pune',\n",
       " 'Mumbai',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(5th block Koramangala)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Siemens Limited',\n",
       " '(2170 Reviews)',\n",
       " 'BRIDGEi2i Analytics Solutions Private Limited',\n",
       " '(40 Reviews)',\n",
       " 'JPMorgan Services India Pvt. Ltd',\n",
       " '(2011 Reviews)',\n",
       " 'Epsilon',\n",
       " '(188 Reviews)',\n",
       " 'Jet2 Travel Technologies Pvt. Ltd.',\n",
       " 'Amploy.io',\n",
       " 'Cunesoft',\n",
       " 'Cunesoft',\n",
       " 'MJB Technology Solutions',\n",
       " 'FIS Global Business Solutions India Pvt. Ltd.',\n",
       " '(1824 Reviews)',\n",
       " 'Motilal Oswal Financial Services',\n",
       " '(554 Reviews)',\n",
       " 'Eaton Corporation',\n",
       " '(407 Reviews)',\n",
       " 'Morgan Stanley Advantage Services',\n",
       " '(263 Reviews)',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " '(18192 Reviews)',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " '(18192 Reviews)',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " '(18192 Reviews)',\n",
       " 'Musubi Management Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " '(9831 Reviews)',\n",
       " 'IBM India Pvt. Limited',\n",
       " '(9831 Reviews)',\n",
       " 'Xceedance',\n",
       " '(141 Reviews)']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data analysis\\nGIT\\nCoding\\nSoftware configuration management\\nConsulting\\nIntegration testing\\nAgile\\nUnit testing',\n",
       " 'Business Analyst\\ndata science\\nAnalytical\\nMachine learning\\nManager Technology\\nApplication development\\nForecasting\\nAnalytics',\n",
       " 'Data Science\\nR\\nArtificial Intelligence\\nExploratory Analysis\\nMarketing Analytics\\nMachine Learning\\nDeep Learning\\nPython',\n",
       " 'IT Skills\\nTesting\\nData Science\\nMachine Learning\\nData analysis\\nFactor analysis\\nAnalytical\\nRisk management',\n",
       " 'IT Skills\\nPython\\nData Science\\nMachine Learning\\nOracle\\nBig Data\\nTableau',\n",
       " 'Data Science\\nApplication Programming\\nSoftware Development\\nAI\\nIT\\nCareer Development\\nMachine Learning\\nStartup',\n",
       " 'Data Science\\nC#\\nNLP\\nArtificial Intelligence\\nData Mining\\n.Net\\nMVC\\nMachine Learning',\n",
       " 'C#\\nLINQ\\nArtificial Intelligence\\nData Management\\nData Mining\\nJQuery\\nMachine Learning\\nNLP',\n",
       " 'Computer science\\nBusiness administration\\nAnalyst\\ndata science\\nMachine learning\\nSAS R\\nCloud\\nTechnology solutions',\n",
       " 'Data Science\\nR\\nSAS\\nArtificial Intelligence\\nStatistical Modeling\\nData Analysis\\nData Visualization\\nMachine Learning',\n",
       " 'Data Science\\nMIS Preparation\\nData Analysis\\nAdvanced Excel\\nData Modeling\\nData Analytics\\nMacros\\nSQL',\n",
       " 'Power Bi\\nMachine Learning\\nPython\\nData Science\\nData Validation\\nBusiness Reporting\\nEDA\\nExcel',\n",
       " 'Unix\\nData analysis\\nLegal compliance\\nWealth management\\nData modeling\\nAnalytical\\nInvestment banking\\nInvestment management',\n",
       " 'IT Skills\\nData Science\\nMachine Learning\\nArtificial Intelligence\\nBusiness administration\\nAnalyst\\nPublishing\\nArchitecture',\n",
       " 'IT Skills\\nData Science\\nMachine Learning\\nArtificial Intelligence\\nAnalyst\\nPublishing\\nArchitecture\\nConsulting',\n",
       " 'Business administration\\nAnalyst\\nPublishing\\nData management\\nArchitecture\\ndata science\\nArtificial Intelligence\\nConsulting',\n",
       " 'Data Science\\nWeb Development\\nIT Skills\\nPython\\nWeb Technologies',\n",
       " 'MLlib\\nKubernetes\\nagile\\nWEKA\\nJava\\nNumPy\\nExcel\\nR',\n",
       " 'IT Skills\\nJava\\nPython\\nSoftware Development\\nTesting\\nData Science\\nMachine Learning\\nComputer science',\n",
       " 'Data analysis\\nReinsurance\\nAnalytical\\nConsulting\\nMySQL\\nData collection\\nWorkflow\\nData quality']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills=driver.find_elements_by_xpath(\"//ul[@class='tags has-description']\")\n",
    "for i in skills:\n",
    "    if i.text is None :\n",
    "        Skills_they_hire_for.append(\"--\") \n",
    "    else:\n",
    "        Skills_they_hire_for.append(i.text)\n",
    "Skills_they_hire_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 34, 20, 20, 20)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_name),len(company_name),len(Skills_they_hire_for),len(Designation),len(job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Skills_they_hire_for</th>\n",
       "      <th>Designation</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Siemens Limited</td>\n",
       "      <td>Data analysis\\nGIT\\nCoding\\nSoftware configura...</td>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUSINESS ANALYST -DATA SCIENCE-CONSUMER</td>\n",
       "      <td>(2170 Reviews)</td>\n",
       "      <td>Business Analyst\\ndata science\\nAnalytical\\nMa...</td>\n",
       "      <td>BUSINESS ANALYST -DATA SCIENCE-CONSUMER</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>BRIDGEi2i Analytics Solutions Private Limited</td>\n",
       "      <td>Data Science\\nR\\nArtificial Intelligence\\nExpl...</td>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Analyst 2</td>\n",
       "      <td>(40 Reviews)</td>\n",
       "      <td>IT Skills\\nTesting\\nData Science\\nMachine Lear...</td>\n",
       "      <td>Data Science Analyst 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science- Associate Data Scientist</td>\n",
       "      <td>JPMorgan Services India Pvt. Ltd</td>\n",
       "      <td>IT Skills\\nPython\\nData Science\\nMachine Learn...</td>\n",
       "      <td>Data Science- Associate Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Intern (remote)</td>\n",
       "      <td>(2011 Reviews)</td>\n",
       "      <td>Data Science\\nApplication Programming\\nSoftwar...</td>\n",
       "      <td>Data Science Intern (remote)</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Software Developer - NLP/ Machine Learn...</td>\n",
       "      <td>Epsilon</td>\n",
       "      <td>Data Science\\nC#\\nNLP\\nArtificial Intelligence...</td>\n",
       "      <td>Senior Software Developer - NLP/ Machine Learn...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Software Developer - Nlp/machine Learni...</td>\n",
       "      <td>(188 Reviews)</td>\n",
       "      <td>C#\\nLINQ\\nArtificial Intelligence\\nData Manage...</td>\n",
       "      <td>Senior Software Developer - Nlp/machine Learni...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Jet2 Travel Technologies Pvt. Ltd.</td>\n",
       "      <td>Computer science\\nBusiness administration\\nAna...</td>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgently hiring For Data science Analysts - Pu...</td>\n",
       "      <td>Amploy.io</td>\n",
       "      <td>Data Science\\nR\\nSAS\\nArtificial Intelligence\\...</td>\n",
       "      <td>Urgently hiring For Data science Analysts - Pu...</td>\n",
       "      <td>Nagpur, Pune, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Opening For Data Data Science Analyst &amp; Data A...</td>\n",
       "      <td>Cunesoft</td>\n",
       "      <td>Data Science\\nMIS Preparation\\nData Analysis\\n...</td>\n",
       "      <td>Opening For Data Data Science Analyst &amp; Data A...</td>\n",
       "      <td>Mumbai, Navi Mumbai, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analyst -Data Science ( Supply Chain)</td>\n",
       "      <td>Cunesoft</td>\n",
       "      <td>Power Bi\\nMachine Learning\\nPython\\nData Scien...</td>\n",
       "      <td>Analyst -Data Science ( Supply Chain)</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science &amp; Analysis (Technology Management)</td>\n",
       "      <td>MJB Technology Solutions</td>\n",
       "      <td>Unix\\nData analysis\\nLegal compliance\\nWealth ...</td>\n",
       "      <td>Data Science &amp; Analysis (Technology Management)</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>FIS Global Business Solutions India Pvt. Ltd.</td>\n",
       "      <td>IT Skills\\nData Science\\nMachine Learning\\nArt...</td>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>(1824 Reviews)</td>\n",
       "      <td>IT Skills\\nData Science\\nMachine Learning\\nArt...</td>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Motilal Oswal Financial Services</td>\n",
       "      <td>Business administration\\nAnalyst\\nPublishing\\n...</td>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Web Development/Data Science Trainee</td>\n",
       "      <td>(554 Reviews)</td>\n",
       "      <td>Data Science\\nWeb Development\\nIT Skills\\nPyth...</td>\n",
       "      <td>Web Development/Data Science Trainee</td>\n",
       "      <td>Bangalore/Bengaluru(5th block Koramangala)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Eaton Corporation</td>\n",
       "      <td>MLlib\\nKubernetes\\nagile\\nWEKA\\nJava\\nNumPy\\nE...</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>(407 Reviews)</td>\n",
       "      <td>IT Skills\\nJava\\nPython\\nSoftware Development\\...</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science Analyst-Insurance Data Sciences</td>\n",
       "      <td>Morgan Stanley Advantage Services</td>\n",
       "      <td>Data analysis\\nReinsurance\\nAnalytical\\nConsul...</td>\n",
       "      <td>Data Science Analyst-Insurance Data Sciences</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_name  \\\n",
       "0                        Senior Data Science Engineer   \n",
       "1             BUSINESS ANALYST -DATA SCIENCE-CONSUMER   \n",
       "2                                Data Science Analyst   \n",
       "3                              Data Science Analyst 2   \n",
       "4              Data Science- Associate Data Scientist   \n",
       "5                        Data Science Intern (remote)   \n",
       "6   Senior Software Developer - NLP/ Machine Learn...   \n",
       "7   Senior Software Developer - Nlp/machine Learni...   \n",
       "8                                Data Science Analyst   \n",
       "9   Urgently hiring For Data science Analysts - Pu...   \n",
       "10  Opening For Data Data Science Analyst & Data A...   \n",
       "11              Analyst -Data Science ( Supply Chain)   \n",
       "12    Data Science & Analysis (Technology Management)   \n",
       "13                        Senior Analyst-Data Science   \n",
       "14                        Senior Analyst-Data Science   \n",
       "15                        Senior Analyst-Data Science   \n",
       "16               Web Development/Data Science Trainee   \n",
       "17                              Data Science Engineer   \n",
       "18                              Data Science Engineer   \n",
       "19       Data Science Analyst-Insurance Data Sciences   \n",
       "\n",
       "                                     company_name  \\\n",
       "0                                 Siemens Limited   \n",
       "1                                  (2170 Reviews)   \n",
       "2   BRIDGEi2i Analytics Solutions Private Limited   \n",
       "3                                    (40 Reviews)   \n",
       "4                JPMorgan Services India Pvt. Ltd   \n",
       "5                                  (2011 Reviews)   \n",
       "6                                         Epsilon   \n",
       "7                                   (188 Reviews)   \n",
       "8              Jet2 Travel Technologies Pvt. Ltd.   \n",
       "9                                       Amploy.io   \n",
       "10                                       Cunesoft   \n",
       "11                                       Cunesoft   \n",
       "12                       MJB Technology Solutions   \n",
       "13  FIS Global Business Solutions India Pvt. Ltd.   \n",
       "14                                 (1824 Reviews)   \n",
       "15               Motilal Oswal Financial Services   \n",
       "16                                  (554 Reviews)   \n",
       "17                              Eaton Corporation   \n",
       "18                                  (407 Reviews)   \n",
       "19              Morgan Stanley Advantage Services   \n",
       "\n",
       "                                 Skills_they_hire_for  \\\n",
       "0   Data analysis\\nGIT\\nCoding\\nSoftware configura...   \n",
       "1   Business Analyst\\ndata science\\nAnalytical\\nMa...   \n",
       "2   Data Science\\nR\\nArtificial Intelligence\\nExpl...   \n",
       "3   IT Skills\\nTesting\\nData Science\\nMachine Lear...   \n",
       "4   IT Skills\\nPython\\nData Science\\nMachine Learn...   \n",
       "5   Data Science\\nApplication Programming\\nSoftwar...   \n",
       "6   Data Science\\nC#\\nNLP\\nArtificial Intelligence...   \n",
       "7   C#\\nLINQ\\nArtificial Intelligence\\nData Manage...   \n",
       "8   Computer science\\nBusiness administration\\nAna...   \n",
       "9   Data Science\\nR\\nSAS\\nArtificial Intelligence\\...   \n",
       "10  Data Science\\nMIS Preparation\\nData Analysis\\n...   \n",
       "11  Power Bi\\nMachine Learning\\nPython\\nData Scien...   \n",
       "12  Unix\\nData analysis\\nLegal compliance\\nWealth ...   \n",
       "13  IT Skills\\nData Science\\nMachine Learning\\nArt...   \n",
       "14  IT Skills\\nData Science\\nMachine Learning\\nArt...   \n",
       "15  Business administration\\nAnalyst\\nPublishing\\n...   \n",
       "16  Data Science\\nWeb Development\\nIT Skills\\nPyth...   \n",
       "17  MLlib\\nKubernetes\\nagile\\nWEKA\\nJava\\nNumPy\\nE...   \n",
       "18  IT Skills\\nJava\\nPython\\nSoftware Development\\...   \n",
       "19  Data analysis\\nReinsurance\\nAnalytical\\nConsul...   \n",
       "\n",
       "                                          Designation  \\\n",
       "0                        Senior Data Science Engineer   \n",
       "1             BUSINESS ANALYST -DATA SCIENCE-CONSUMER   \n",
       "2                                Data Science Analyst   \n",
       "3                              Data Science Analyst 2   \n",
       "4              Data Science- Associate Data Scientist   \n",
       "5                        Data Science Intern (remote)   \n",
       "6   Senior Software Developer - NLP/ Machine Learn...   \n",
       "7   Senior Software Developer - Nlp/machine Learni...   \n",
       "8                                Data Science Analyst   \n",
       "9   Urgently hiring For Data science Analysts - Pu...   \n",
       "10  Opening For Data Data Science Analyst & Data A...   \n",
       "11              Analyst -Data Science ( Supply Chain)   \n",
       "12    Data Science & Analysis (Technology Management)   \n",
       "13                        Senior Analyst-Data Science   \n",
       "14                        Senior Analyst-Data Science   \n",
       "15                        Senior Analyst-Data Science   \n",
       "16               Web Development/Data Science Trainee   \n",
       "17                              Data Science Engineer   \n",
       "18                              Data Science Engineer   \n",
       "19       Data Science Analyst-Insurance Data Sciences   \n",
       "\n",
       "                                         job_location  \n",
       "0                                 Bangalore/Bengaluru  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                         Mumbai, Bangalore/Bengaluru  \n",
       "3                                 Bangalore/Bengaluru  \n",
       "4                                                Pune  \n",
       "5   Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8                                                Pune  \n",
       "9                    Nagpur, Pune, Mumbai (All Areas)  \n",
       "10            Mumbai, Navi Mumbai, Mumbai (All Areas)  \n",
       "11                                               Pune  \n",
       "12                                             Mumbai  \n",
       "13                                Bangalore/Bengaluru  \n",
       "14                                Bangalore/Bengaluru  \n",
       "15                                Bangalore/Bengaluru  \n",
       "16         Bangalore/Bengaluru(5th block Koramangala)  \n",
       "17                                Bangalore/Bengaluru  \n",
       "18                                Bangalore/Bengaluru  \n",
       "19                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"Job_name\":job_name[0:20],\"company_name\":company_name[0:20],\"Skills_they_hire_for\":Skills_they_hire_for[0:20],\n",
    "                 \"Designation\":Designation,\"job_location\":job_location[0:20]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8.Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')\n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "name1=driver.find_elements_by_xpath(\"//td[@class='left'][2]\")\n",
    "for i in name1:\n",
    "    Book_name.append(i.text)  \n",
    "     \n",
    "\n",
    "author=driver.find_elements_by_xpath(\"//td[@class='left'][3]\")\n",
    "for i in author:\n",
    "    Author_name.append(i.text)  \n",
    "     \n",
    "\n",
    "volume=driver.find_elements_by_xpath(\"//td[@class='left'][4]\")\n",
    "for i in volume:\n",
    "    Volumes_sold.append(i.text)  \n",
    "     \n",
    "\n",
    "publisher=driver.find_elements_by_xpath(\"//td[@class='left'][5]\")\n",
    "for i in publisher:\n",
    "    Publisher.append(i.text) \n",
    "\n",
    "gen=driver.find_elements_by_xpath(\"//td[@class='last left']\")\n",
    "for i in gen:\n",
    "    Genre.append(i.text) \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df[\"Book name\"]=Book_name\n",
    "df[\"Author name\"]=Author_name\n",
    "df[\"Volumes sold\"]=Volumes_sold\n",
    "df[\"Publisher\"]=Publisher\n",
    "df[\"Genre\"]=Genre\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Best seller Books.csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9.Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Game of Thrones (2011–2019)',\n",
       " '2. Stranger Things (2016– )',\n",
       " '3. The Walking Dead (2010–2022)',\n",
       " '4. 13 Reasons Why (2017–2020)',\n",
       " '5. The 100 (2014–2020)',\n",
       " '6. Orange Is the New Black (2013–2019)',\n",
       " '7. Riverdale (2017– )',\n",
       " \"8. Grey's Anatomy (2005– )\",\n",
       " '9. The Flash (2014– )',\n",
       " '10. Arrow (2012–2020)',\n",
       " '11. Money Heist (2017–2021)',\n",
       " '12. The Big Bang Theory (2007–2019)',\n",
       " '13. Black Mirror (2011– )',\n",
       " '14. Sherlock (2010–2017)',\n",
       " '15. Vikings (2013–2020)',\n",
       " '16. Pretty Little Liars (2010–2017)',\n",
       " '17. The Vampire Diaries (2009–2017)',\n",
       " '18. American Horror Story (2011– )',\n",
       " '19. Breaking Bad (2008–2013)',\n",
       " '20. Lucifer (2016– )',\n",
       " '21. Supernatural (2005–2020)',\n",
       " '22. Prison Break (2005–2017)',\n",
       " '23. How to Get Away with Murder (2014–2020)',\n",
       " '24. Teen Wolf (2011–2017)',\n",
       " '25. The Simpsons (1989– )',\n",
       " '26. Once Upon a Time (2011–2018)',\n",
       " '27. Narcos (2015–2017)',\n",
       " '28. Daredevil (2015–2018)',\n",
       " '29. Friends (1994–2004)',\n",
       " '30. How I Met Your Mother (2005–2014)',\n",
       " '31. Suits (2011–2019)',\n",
       " '32. Mr. Robot (2015–2019)',\n",
       " '33. The Originals (2013–2018)',\n",
       " '34. Supergirl (2015–2021)',\n",
       " '35. Gossip Girl (2007–2012)',\n",
       " '36. Sense8 (2015–2018)',\n",
       " '37. Gotham (2014–2019)',\n",
       " '38. Westworld (2016– )',\n",
       " '39. Jessica Jones (2015–2019)',\n",
       " '40. Modern Family (2009–2020)',\n",
       " '41. Rick and Morty (2013– )',\n",
       " '42. Shadowhunters (2016–2019)',\n",
       " '43. The End of the F***ing World (2017–2019)',\n",
       " '44. House of Cards (2013–2018)',\n",
       " '45. Dark (2017–2020)',\n",
       " '46. Elite (2018– )',\n",
       " '47. Sex Education (2019– )',\n",
       " '48. Shameless (2011–2021)',\n",
       " '49. New Girl (2011–2018)',\n",
       " '50. Agents of S.H.I.E.L.D. (2013–2020)',\n",
       " '51. You (2018– )',\n",
       " '52. Dexter (2006–2021)',\n",
       " '53. Fear the Walking Dead (2015– )',\n",
       " '54. Family Guy (1999– )',\n",
       " '55. The Blacklist (2013– )',\n",
       " '56. Lost (2004–2010)',\n",
       " '57. Peaky Blinders (2013– )',\n",
       " '58. House (2004–2012)',\n",
       " '59. Quantico (2015–2018)',\n",
       " '60. Orphan Black (2013–2017)',\n",
       " '61. Homeland (2011–2020)',\n",
       " '62. Blindspot (2015–2020)',\n",
       " \"63. DC's Legends of Tomorrow (2016– )\",\n",
       " \"64. The Handmaid's Tale (2017– )\",\n",
       " '65. Chilling Adventures of Sabrina (2018–2020)',\n",
       " '66. The Good Doctor (2017– )',\n",
       " '67. Jane the Virgin (2014–2019)',\n",
       " '68. Glee (2009–2015)',\n",
       " '69. South Park (1997– )',\n",
       " '70. Brooklyn Nine-Nine (2013–2022)',\n",
       " '71. Under the Dome (2013–2015)',\n",
       " '72. The Umbrella Academy (2019– )',\n",
       " '73. True Detective (2014–2019)',\n",
       " '74. The OA (2016–2019)',\n",
       " '75. Desperate Housewives (2004–2012)',\n",
       " '76. Better Call Saul (2015– )',\n",
       " '77. Bates Motel (2013–2017)',\n",
       " '78. The Punisher (2017–2019)',\n",
       " '79. Atypical (2017–2021)',\n",
       " '80. Dynasty (2017– )',\n",
       " '81. This Is Us (2016–2022)',\n",
       " '82. The Good Place (2016–2020)',\n",
       " '83. Iron Fist (2017–2018)',\n",
       " '84. The Rain (2018–2020)',\n",
       " '85. Mindhunter (2017–2019)',\n",
       " '86. Revenge (2011–2015)',\n",
       " '87. Luke Cage (2016–2018)',\n",
       " '88. Scandal (2012–2018)',\n",
       " '89. The Defenders (2017)',\n",
       " '90. Big Little Lies (2017–2019)',\n",
       " '91. Insatiable (2018–2019)',\n",
       " '92. The Mentalist (2008–2015)',\n",
       " '93. The Crown (2016– )',\n",
       " '94. Chernobyl (2019)',\n",
       " '95. iZombie (2015–2019)',\n",
       " '96. Reign (2013–2017)',\n",
       " '97. A Series of Unfortunate Events (2017–2019)',\n",
       " '98. Criminal Minds (2005–2020)',\n",
       " '99. Scream: The TV Series (2015–2019)',\n",
       " '100. The Haunting of Hill House (2018)']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']\")\n",
    "for i in name:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "span=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in span:\n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014– )',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011– )',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016– )',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016– )',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2021)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013– )',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016– )',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2022)',\n",
       " '(2013–2015)',\n",
       " '(2019– )',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015– )',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017– )',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005–2020)',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Mystery',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Fantasy',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']\")\n",
    "for i in rate:\n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text.replace(\"Rate\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '8',\n",
       " '6.8',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.4',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '8.6',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.2',\n",
       " '6.2',\n",
       " '7.4',\n",
       " '8.3',\n",
       " '7.8',\n",
       " '8.6',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '9.2',\n",
       " '6.6',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.8',\n",
       " '7.5',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '7.7',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.6',\n",
       " '6.9',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.4',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.5',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '6.7',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.6',\n",
       " '8',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.5',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.6',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '8',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "for i in time:\n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[2]\")\n",
    "for i in vote:\n",
    "    if i.text is None :\n",
    "         Votes.append(\"--\") \n",
    "    else:\n",
    "         Votes.append(i.text.replace(\"|\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,823,318',\n",
       " '863,868',\n",
       " '874,508',\n",
       " '262,690',\n",
       " '224,030',\n",
       " '282,657',\n",
       " '125,048',\n",
       " '261,183',\n",
       " '314,406',\n",
       " '412,330',\n",
       " '331,000',\n",
       " '737,265',\n",
       " '462,394',\n",
       " '830,079',\n",
       " '451,458',\n",
       " '154,696',\n",
       " '290,389',\n",
       " '282,485',\n",
       " '1,526,215',\n",
       " '252,367',\n",
       " '399,840',\n",
       " '487,567',\n",
       " '134,223',\n",
       " '131,035',\n",
       " '372,429',\n",
       " '211,217',\n",
       " '370,649',\n",
       " '370,965',\n",
       " '863,718',\n",
       " '617,940',\n",
       " '371,255',\n",
       " '342,128',\n",
       " '121,084',\n",
       " '114,280',\n",
       " '157,672',\n",
       " '142,757',\n",
       " '214,876',\n",
       " '439,715',\n",
       " '196,365',\n",
       " '370,926',\n",
       " '394,999',\n",
       " '55,383',\n",
       " '154,281',\n",
       " '473,658',\n",
       " '305,083',\n",
       " '53,678',\n",
       " '171,174',\n",
       " '211,003',\n",
       " '197,938',\n",
       " '203,549',\n",
       " '153,613',\n",
       " '658,335',\n",
       " '116,395',\n",
       " '310,047',\n",
       " '207,589',\n",
       " '507,025',\n",
       " '380,007',\n",
       " '422,490',\n",
       " '57,842',\n",
       " '103,416',\n",
       " '320,163',\n",
       " '67,618',\n",
       " '94,424',\n",
       " '186,542',\n",
       " '81,232',\n",
       " '67,586',\n",
       " '40,644',\n",
       " '138,817',\n",
       " '337,360',\n",
       " '242,245',\n",
       " '102,139',\n",
       " '170,807',\n",
       " '510,651',\n",
       " '93,549',\n",
       " '118,549',\n",
       " '341,026',\n",
       " '99,167',\n",
       " '191,464',\n",
       " '64,285',\n",
       " '16,102',\n",
       " '114,433',\n",
       " '123,784',\n",
       " '117,475',\n",
       " '32,291',\n",
       " '230,239',\n",
       " '114,119',\n",
       " '119,082',\n",
       " '68,213',\n",
       " '93,406',\n",
       " '164,707',\n",
       " '23,623',\n",
       " '168,716',\n",
       " '166,095',\n",
       " '581,747',\n",
       " '61,598',\n",
       " '44,578',\n",
       " '55,069',\n",
       " '167,730',\n",
       " '34,886',\n",
       " '191,414']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Votes=[x for x in Votes if x != ' ']\n",
    "Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_span),len(Genre),len(Run_time),len(Ratings),len(Votes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,823,318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016– )</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>863,868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>874,508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005–2020)</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name    Year_span  \\\n",
       "0                   1. Game of Thrones (2011–2019)  (2011–2019)   \n",
       "1                      2. Stranger Things (2016– )     (2016– )   \n",
       "2                  3. The Walking Dead (2010–2022)  (2010–2022)   \n",
       "3                    4. 13 Reasons Why (2017–2020)  (2017–2020)   \n",
       "4                           5. The 100 (2014–2020)  (2014–2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013–2017)  (2013–2017)   \n",
       "96  97. A Series of Unfortunate Events (2017–2019)  (2017–2019)   \n",
       "97                  98. Criminal Minds (2005–2020)  (2005–2020)   \n",
       "98           99. Scream: The TV Series (2015–2019)  (2015–2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run time Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.3  1,823,318  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7    863,868  \n",
       "2    Drama, Horror, Thriller   44 min     8.2    874,508  \n",
       "3   Drama, Mystery, Thriller   60 min     7.6    262,690  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    224,030  \n",
       "..                       ...      ...     ...        ...  \n",
       "95            Drama, Fantasy   42 min     7.5     44,578  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     55,069  \n",
       "97     Crime, Drama, Mystery   42 min       8    167,730  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     34,886  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    191,414  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Name']=Name\n",
    "df['Year_span']=Year_span\n",
    "df['Genre']=Genre\n",
    "df['Run time']=Run_time\n",
    "df['Ratings']=Ratings\n",
    "df['Votes']=Votes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Top 100 most watched tv shows of all time.csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10.Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge(r'msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://archive.ics.uci.edu/ml/index.php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view all datasets\n",
    "view=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\")\n",
    "view.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")\n",
    "for i in name:\n",
    "    if i.text is None :\n",
    "         Dataset_name.append(\"--\") \n",
    "    else:\n",
    "         Dataset_name.append(i.text)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=driver.find_elements_by_xpath(\"p[@class='normal']\") \n",
    "for i in dtype:\n",
    "    if i.text is None :\n",
    "         Data_type.append(\"--\") \n",
    "    else:\n",
    "         Data_type.append(i.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "task=driver.find_elements_by_xpath(\"p[@class='normal']\") \n",
    "for i in task:\n",
    "    if i.text is None :\n",
    "         Task.append(\"--\") \n",
    "    else:\n",
    "         Task.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
